From 6462993bb2453de2c10e1324467d9e26e31ad525 Mon Sep 17 00:00:00 2001
From: Cursor Agent <cursoragent@cursor.com>
Date: Wed, 28 Jan 2026 07:10:54 +0000
Subject: [PATCH] feat(v0.6.5): Add features from ai-lib-python

New modules:
- embeddings/: Embedding client, vector operations
- cache/: Response caching with multiple backends
- tokens/: Token counting and cost estimation
- batch/: Request batching and execution
- plugins/: Plugin system with hooks and middleware

Enhanced telemetry:
- RatingFeedback, ThumbsFeedback, TextFeedback, etc.
- InMemoryFeedbackSink, ConsoleFeedbackSink, CompositeFeedbackSink
- Global feedback sink management

Dependencies:
- Added sha2, once_cell
---
 CHANGELOG.md              |  42 ++++++
 Cargo.lock                | 271 +++++---------------------------------
 Cargo.toml                |   4 +-
 src/batch/collector.rs    |  63 +++++++++
 src/batch/executor.rs     |  61 +++++++++
 src/batch/mod.rs          |   7 +
 src/cache/backend.rs      |  82 ++++++++++++
 src/cache/key.rs          |  62 +++++++++
 src/cache/manager.rs      |  81 ++++++++++++
 src/cache/mod.rs          |   9 ++
 src/embeddings/client.rs  |  80 +++++++++++
 src/embeddings/mod.rs     |  20 +++
 src/embeddings/types.rs   | 151 +++++++++++++++++++++
 src/embeddings/vectors.rs | 111 ++++++++++++++++
 src/error.rs              |  34 +++++
 src/lib.rs                |   5 +
 src/plugins/base.rs       |  63 +++++++++
 src/plugins/hooks.rs      |  57 ++++++++
 src/plugins/middleware.rs |  49 +++++++
 src/plugins/mod.rs        |  11 ++
 src/plugins/registry.rs   |  61 +++++++++
 src/telemetry/mod.rs      | 145 +++++++++++++++++---
 src/tokens/counter.rs     |  91 +++++++++++++
 src/tokens/mod.rs         |   7 +
 src/tokens/pricing.rs     |  35 +++++
 25 files changed, 1348 insertions(+), 254 deletions(-)
 create mode 100644 src/batch/collector.rs
 create mode 100644 src/batch/executor.rs
 create mode 100644 src/batch/mod.rs
 create mode 100644 src/cache/backend.rs
 create mode 100644 src/cache/key.rs
 create mode 100644 src/cache/manager.rs
 create mode 100644 src/cache/mod.rs
 create mode 100644 src/embeddings/client.rs
 create mode 100644 src/embeddings/mod.rs
 create mode 100644 src/embeddings/types.rs
 create mode 100644 src/embeddings/vectors.rs
 create mode 100644 src/plugins/base.rs
 create mode 100644 src/plugins/hooks.rs
 create mode 100644 src/plugins/middleware.rs
 create mode 100644 src/plugins/mod.rs
 create mode 100644 src/plugins/registry.rs
 create mode 100644 src/tokens/counter.rs
 create mode 100644 src/tokens/mod.rs
 create mode 100644 src/tokens/pricing.rs

diff --git a/CHANGELOG.md b/CHANGELOG.md
index 725be47..a41d265 100644
--- a/CHANGELOG.md
+++ b/CHANGELOG.md
@@ -2,6 +2,48 @@
 
 All notable changes to this project will be documented in this file.
 
+## 0.6.5 - 2026-01-27
+
+### Added (Features from ai-lib-python)
+
+This release adds features learned from the Python reference implementation.
+
+#### Embedding Support (`embeddings/`)
+- `EmbeddingClient`, `EmbeddingClientBuilder` for generating embeddings
+- `Embedding`, `EmbeddingRequest`, `EmbeddingResponse`, `EmbeddingUsage` types
+- Vector operations: `cosine_similarity`, `dot_product`, `euclidean_distance`, `manhattan_distance`
+- `normalize_vector`, `average_vectors`, `weighted_average_vectors`, `find_most_similar`
+
+#### Response Caching (`cache/`)
+- `CacheBackend` trait with `MemoryCache` and `NullCache` implementations
+- `CacheManager` with TTL support and statistics
+- `CacheKey`, `CacheKeyGenerator` for deterministic cache keys
+
+#### Token Counting (`tokens/`)
+- `TokenCounter` trait with `CharacterEstimator`, `AnthropicEstimator`, `CachingCounter`
+- `ModelPricing` with pre-configured pricing for GPT-4o, Claude models
+- `CostEstimate` for cost calculation
+
+#### Extended Feedback System (`telemetry/`)
+- New feedback types: `RatingFeedback`, `ThumbsFeedback`, `TextFeedback`, `CorrectionFeedback`, `RegenerateFeedback`, `StopFeedback`
+- New sinks: `InMemoryFeedbackSink`, `ConsoleFeedbackSink`, `CompositeFeedbackSink`
+- Global sink management: `get_feedback_sink()`, `set_feedback_sink()`, `report_feedback()`
+
+#### Request Batching (`batch/`)
+- `BatchConfig`, `BatchCollector` for request accumulation
+- `BatchExecutor`, `BatchResult` for batch execution with configurable strategies
+
+#### Plugin System (`plugins/`)
+- `Plugin` trait with lifecycle hooks
+- `PluginContext`, `PluginPriority`, `CompositePlugin`
+- `PluginRegistry` for centralized management
+- Hook system: `HookType`, `Hook`, `HookManager`
+- Middleware: `Middleware`, `MiddlewareChain`, `MiddlewareContext`
+
+### Dependencies
+- Added `sha2` for cache key hashing
+- Added `once_cell` for lazy static initialization
+
 ## 0.6.0 - 2026-01-27
 
 ### Added
diff --git a/Cargo.lock b/Cargo.lock
index 9ed0248..6faecdf 100644
--- a/Cargo.lock
+++ b/Cargo.lock
@@ -38,7 +38,7 @@ dependencies = [
 
 [[package]]
 name = "ai-lib-rust"
-version = "0.6.0"
+version = "0.6.5"
 dependencies = [
  "anyhow",
  "arc-swap",
@@ -52,10 +52,12 @@ dependencies = [
  "lru",
  "mockito",
  "notify",
+ "once_cell",
  "reqwest 0.11.27",
  "serde",
  "serde_json",
  "serde_yaml",
+ "sha2",
  "thiserror",
  "tokio",
  "tokio-stream",
@@ -625,17 +627,6 @@ dependencies = [
  "subtle",
 ]
 
-[[package]]
-name = "displaydoc"
-version = "0.2.5"
-source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "97369cbbc041bc366949bc74d34658d6cda5621039731c6310521892a3a20ae0"
-dependencies = [
- "proc-macro2",
- "quote",
- "syn 2.0.112",
-]
-
 [[package]]
 name = "encoding_rs"
 version = "0.8.35"
@@ -1205,106 +1196,14 @@ dependencies = [
  "tracing",
 ]
 
-[[package]]
-name = "icu_collections"
-version = "2.1.1"
-source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "4c6b649701667bbe825c3b7e6388cb521c23d88644678e83c0c4d0a621a34b43"
-dependencies = [
- "displaydoc",
- "potential_utf",
- "yoke",
- "zerofrom",
- "zerovec",
-]
-
-[[package]]
-name = "icu_locale_core"
-version = "2.1.1"
-source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "edba7861004dd3714265b4db54a3c390e880ab658fec5f7db895fae2046b5bb6"
-dependencies = [
- "displaydoc",
- "litemap",
- "tinystr",
- "writeable",
- "zerovec",
-]
-
-[[package]]
-name = "icu_normalizer"
-version = "2.1.1"
-source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "5f6c8828b67bf8908d82127b2054ea1b4427ff0230ee9141c54251934ab1b599"
-dependencies = [
- "icu_collections",
- "icu_normalizer_data",
- "icu_properties",
- "icu_provider",
- "smallvec",
- "zerovec",
-]
-
-[[package]]
-name = "icu_normalizer_data"
-version = "2.1.1"
-source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "7aedcccd01fc5fe81e6b489c15b247b8b0690feb23304303a9e560f37efc560a"
-
-[[package]]
-name = "icu_properties"
-version = "2.1.2"
-source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "020bfc02fe870ec3a66d93e677ccca0562506e5872c650f893269e08615d74ec"
-dependencies = [
- "icu_collections",
- "icu_locale_core",
- "icu_properties_data",
- "icu_provider",
- "zerotrie",
- "zerovec",
-]
-
-[[package]]
-name = "icu_properties_data"
-version = "2.1.2"
-source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "616c294cf8d725c6afcd8f55abc17c56464ef6211f9ed59cccffe534129c77af"
-
-[[package]]
-name = "icu_provider"
-version = "2.1.1"
-source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "85962cf0ce02e1e0a629cc34e7ca3e373ce20dda4c4d7294bbd0bf1fdb59e614"
-dependencies = [
- "displaydoc",
- "icu_locale_core",
- "writeable",
- "yoke",
- "zerofrom",
- "zerotrie",
- "zerovec",
-]
-
 [[package]]
 name = "idna"
-version = "1.1.0"
-source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "3b0875f23caa03898994f6ddc501886a45c7d3d62d04d2d90788d47be1b1e4de"
-dependencies = [
- "idna_adapter",
- "smallvec",
- "utf8_iter",
-]
-
-[[package]]
-name = "idna_adapter"
-version = "1.2.1"
+version = "0.5.0"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "3acae9609540aa318d1bc588455225fb2085b9ed0c4f6bd0d9d5bcd86f1a0344"
+checksum = "634d9b1461af396cad843f47fdba5597a4f9e6ddd4bfb6ff5d85028c25cb12f6"
 dependencies = [
- "icu_normalizer",
- "icu_properties",
+ "unicode-bidi",
+ "unicode-normalization",
 ]
 
 [[package]]
@@ -1529,12 +1428,6 @@ version = "0.11.0"
 source = "registry+https://github.com/rust-lang/crates.io-index"
 checksum = "df1d3c3b53da64cf5760482273a98e575c651a67eec7f77df96b5b642de8f039"
 
-[[package]]
-name = "litemap"
-version = "0.8.1"
-source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "6373607a59f0be73a39b6fe456b8192fcc3585f602af20751600e974dd455e77"
-
 [[package]]
 name = "lock_api"
 version = "0.4.14"
@@ -1890,15 +1783,6 @@ dependencies = [
  "windows-sys 0.61.2",
 ]
 
-[[package]]
-name = "potential_utf"
-version = "0.1.4"
-source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "b73949432f5e2a09657003c25bca5e19a0e9c84f8058ca374f49e0ebe605af77"
-dependencies = [
- "zerovec",
-]
-
 [[package]]
 name = "powerfmt"
 version = "0.2.0"
@@ -2469,12 +2353,6 @@ dependencies = [
  "windows-sys 0.60.2",
 ]
 
-[[package]]
-name = "stable_deref_trait"
-version = "1.2.1"
-source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "6ce2be8dc25455e1f91df71bfa12ad37d7af1092ae736f3a6cd0e37bc7810596"
-
 [[package]]
 name = "static_assertions"
 version = "1.1.0"
@@ -2530,17 +2408,6 @@ dependencies = [
  "futures-core",
 ]
 
-[[package]]
-name = "synstructure"
-version = "0.13.2"
-source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "728a70f3dbaf5bab7f0c4b1ac8d7ae5ea60a4b5549c8a5914361c99147a709d2"
-dependencies = [
- "proc-macro2",
- "quote",
- "syn 2.0.112",
-]
-
 [[package]]
 name = "system-configuration"
 version = "0.5.1"
@@ -2635,15 +2502,20 @@ dependencies = [
 ]
 
 [[package]]
-name = "tinystr"
-version = "0.8.2"
+name = "tinyvec"
+version = "1.10.0"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "42d3e9c45c09de15d06dd8acf5f4e0e399e85927b7f00711024eb7ae10fa4869"
+checksum = "bfa5fdc3bce6191a1dbc8c02d5c8bffcf557bafa17c124c5264a458f1b0613fa"
 dependencies = [
- "displaydoc",
- "zerovec",
+ "tinyvec_macros",
 ]
 
+[[package]]
+name = "tinyvec_macros"
+version = "0.1.1"
+source = "registry+https://github.com/rust-lang/crates.io-index"
+checksum = "1f3ccbac311fea05f86f61904b462b55fb3df8837a366dfc601a0161d0532f20"
+
 [[package]]
 name = "tokio"
 version = "1.48.0"
@@ -2865,12 +2737,27 @@ dependencies = [
  "winapi",
 ]
 
+[[package]]
+name = "unicode-bidi"
+version = "0.3.18"
+source = "registry+https://github.com/rust-lang/crates.io-index"
+checksum = "5c1cb5db39152898a79168971543b1cb5020dff7fe43c8dc468b0885f5e29df5"
+
 [[package]]
 name = "unicode-ident"
 version = "1.0.22"
 source = "registry+https://github.com/rust-lang/crates.io-index"
 checksum = "9312f7c4f6ff9069b165498234ce8be658059c6728633667c526e27dc2cf1df5"
 
+[[package]]
+name = "unicode-normalization"
+version = "0.1.25"
+source = "registry+https://github.com/rust-lang/crates.io-index"
+checksum = "5fd4f6878c9cb28d874b009da9e8d183b5abc80117c40bbd187a1fde336be6e8"
+dependencies = [
+ "tinyvec",
+]
+
 [[package]]
 name = "unsafe-libyaml"
 version = "0.2.11"
@@ -2885,22 +2772,15 @@ checksum = "8ecb6da28b8a351d773b68d5825ac39017e680750f980f3a1a85cd8dd28a47c1"
 
 [[package]]
 name = "url"
-version = "2.5.7"
+version = "2.5.0"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "08bc136a29a3d1758e07a9cca267be308aeebf5cfd5a10f3f67ab2097683ef5b"
+checksum = "31e6302e3bb753d46e83516cae55ae196fc0c309407cf11ab35cc51a4c2a4633"
 dependencies = [
  "form_urlencoded",
  "idna",
  "percent-encoding",
- "serde",
 ]
 
-[[package]]
-name = "utf8_iter"
-version = "1.0.4"
-source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "b6c140620e7ffbb22c2dee59cafe6084a59b5ffc27a8859a5f0d494b5d52b6be"
-
 [[package]]
 name = "utf8parse"
 version = "0.2.2"
@@ -3350,12 +3230,6 @@ version = "0.46.0"
 source = "registry+https://github.com/rust-lang/crates.io-index"
 checksum = "f17a85883d4e6d00e8a97c586de764dabcc06133f7f1d55dce5cdc070ad7fe59"
 
-[[package]]
-name = "writeable"
-version = "0.6.2"
-source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "9edde0db4769d2dc68579893f2306b26c6ecfbe0ef499b013d731b7b9247e0b9"
-
 [[package]]
 name = "xdg-home"
 version = "1.3.0"
@@ -3366,29 +3240,6 @@ dependencies = [
  "windows-sys 0.59.0",
 ]
 
-[[package]]
-name = "yoke"
-version = "0.8.1"
-source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "72d6e5c6afb84d73944e5cedb052c4680d5657337201555f9f2a16b7406d4954"
-dependencies = [
- "stable_deref_trait",
- "yoke-derive",
- "zerofrom",
-]
-
-[[package]]
-name = "yoke-derive"
-version = "0.8.1"
-source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "b659052874eb698efe5b9e8cf382204678a0086ebf46982b79d6ca3182927e5d"
-dependencies = [
- "proc-macro2",
- "quote",
- "syn 2.0.112",
- "synstructure",
-]
-
 [[package]]
 name = "zbus"
 version = "3.15.2"
@@ -3475,60 +3326,6 @@ dependencies = [
  "syn 2.0.112",
 ]
 
-[[package]]
-name = "zerofrom"
-version = "0.1.6"
-source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "50cc42e0333e05660c3587f3bf9d0478688e15d870fab3346451ce7f8c9fbea5"
-dependencies = [
- "zerofrom-derive",
-]
-
-[[package]]
-name = "zerofrom-derive"
-version = "0.1.6"
-source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "d71e5d6e06ab090c67b5e44993ec16b72dcbaabc526db883a360057678b48502"
-dependencies = [
- "proc-macro2",
- "quote",
- "syn 2.0.112",
- "synstructure",
-]
-
-[[package]]
-name = "zerotrie"
-version = "0.2.3"
-source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "2a59c17a5562d507e4b54960e8569ebee33bee890c70aa3fe7b97e85a9fd7851"
-dependencies = [
- "displaydoc",
- "yoke",
- "zerofrom",
-]
-
-[[package]]
-name = "zerovec"
-version = "0.11.5"
-source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "6c28719294829477f525be0186d13efa9a3c602f7ec202ca9e353d310fb9a002"
-dependencies = [
- "yoke",
- "zerofrom",
- "zerovec-derive",
-]
-
-[[package]]
-name = "zerovec-derive"
-version = "0.11.2"
-source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "eadce39539ca5cb3985590102671f2567e659fca9666581ad3411d59207951f3"
-dependencies = [
- "proc-macro2",
- "quote",
- "syn 2.0.112",
-]
-
 [[package]]
 name = "zmij"
 version = "1.0.5"
diff --git a/Cargo.toml b/Cargo.toml
index 4a130ed..a81f58e 100644
--- a/Cargo.toml
+++ b/Cargo.toml
@@ -1,6 +1,6 @@
 [package]
 name = "ai-lib-rust"
-version = "0.6.0"
+version = "0.6.5"
 edition = "2021"
 authors = ["AI-Protocol Team"]
 license = "MIT OR Apache-2.0"
@@ -65,6 +65,8 @@ lru = "0.12"
 keyring = "2.0"
 uuid = { version = "1.6", features = ["v4"] }
 base64 = "0.22"
+sha2 = "0.10"
+once_cell = "1.19"
 
 [dev-dependencies]
 tokio-test = "0.4"
diff --git a/src/batch/collector.rs b/src/batch/collector.rs
new file mode 100644
index 0000000..e5b1b79
--- /dev/null
+++ b/src/batch/collector.rs
@@ -0,0 +1,63 @@
+//! Batch collector.
+
+use std::collections::VecDeque;
+use std::sync::{Arc, RwLock};
+use std::time::{Duration, Instant};
+
+#[derive(Debug, Clone)]
+pub struct BatchConfig { pub max_batch_size: usize, pub max_wait_time: Duration, pub auto_flush: bool }
+impl Default for BatchConfig { fn default() -> Self { Self { max_batch_size: 10, max_wait_time: Duration::from_secs(5), auto_flush: true } } }
+impl BatchConfig {
+    pub fn new() -> Self { Self::default() }
+    pub fn with_max_batch_size(mut self, s: usize) -> Self { self.max_batch_size = s; self }
+    pub fn with_auto_flush(mut self, a: bool) -> Self { self.auto_flush = a; self }
+}
+
+#[derive(Debug, Clone)]
+pub struct BatchItem<T> { pub data: T, pub added_at: Instant, pub request_id: Option<String>, pub priority: i32 }
+impl<T> BatchItem<T> {
+    pub fn new(data: T) -> Self { Self { data, added_at: Instant::now(), request_id: None, priority: 0 } }
+    pub fn with_request_id(mut self, id: impl Into<String>) -> Self { self.request_id = Some(id.into()); self }
+    pub fn with_priority(mut self, p: i32) -> Self { self.priority = p; self }
+}
+
+pub struct BatchCollector<T> { config: BatchConfig, items: Arc<RwLock<VecDeque<BatchItem<T>>>>, batch_start: Arc<RwLock<Option<Instant>>> }
+
+impl<T: Clone> BatchCollector<T> {
+    pub fn new(config: BatchConfig) -> Self { Self { config, items: Arc::new(RwLock::new(VecDeque::new())), batch_start: Arc::new(RwLock::new(None)) } }
+
+    pub fn add(&self, item: BatchItem<T>) -> BatchAddResult {
+        let mut items = self.items.write().unwrap();
+        let mut start = self.batch_start.write().unwrap();
+        if items.is_empty() { *start = Some(Instant::now()); }
+        items.push_back(item);
+        let count = items.len();
+        if self.config.auto_flush && count >= self.config.max_batch_size { BatchAddResult::ShouldFlush { count } } else { BatchAddResult::Added { count } }
+    }
+
+    pub fn add_data(&self, data: T) -> BatchAddResult { self.add(BatchItem::new(data)) }
+
+    pub fn should_flush(&self) -> bool {
+        let items = self.items.read().unwrap();
+        let start = self.batch_start.read().unwrap();
+        if items.is_empty() { return false; }
+        if items.len() >= self.config.max_batch_size { return true; }
+        if let Some(s) = *start { if s.elapsed() >= self.config.max_wait_time { return true; } }
+        false
+    }
+
+    pub fn drain(&self) -> Vec<BatchItem<T>> {
+        let mut items = self.items.write().unwrap();
+        let mut start = self.batch_start.write().unwrap();
+        *start = None;
+        items.drain(..).collect()
+    }
+
+    pub fn len(&self) -> usize { self.items.read().unwrap().len() }
+    pub fn is_empty(&self) -> bool { self.len() == 0 }
+    pub fn clear(&self) { self.items.write().unwrap().clear(); *self.batch_start.write().unwrap() = None; }
+}
+
+#[derive(Debug, Clone, PartialEq, Eq)]
+pub enum BatchAddResult { Added { count: usize }, ShouldFlush { count: usize } }
+impl BatchAddResult { pub fn should_flush(&self) -> bool { matches!(self, BatchAddResult::ShouldFlush { .. }) } pub fn count(&self) -> usize { match self { BatchAddResult::Added { count } | BatchAddResult::ShouldFlush { count } => *count } } }
diff --git a/src/batch/executor.rs b/src/batch/executor.rs
new file mode 100644
index 0000000..b544d1e
--- /dev/null
+++ b/src/batch/executor.rs
@@ -0,0 +1,61 @@
+//! Batch executor.
+
+use std::time::{Duration, Instant};
+use super::collector::BatchItem;
+
+#[derive(Debug, Clone)]
+pub struct BatchResult<T, E> { pub successes: Vec<(usize, T)>, pub failures: Vec<(usize, E)>, pub execution_time: Duration, pub total_processed: usize }
+
+impl<T, E> BatchResult<T, E> {
+    pub fn new() -> Self { Self { successes: Vec::new(), failures: Vec::new(), execution_time: Duration::ZERO, total_processed: 0 } }
+    pub fn add_success(&mut self, i: usize, r: T) { self.successes.push((i, r)); }
+    pub fn add_failure(&mut self, i: usize, e: E) { self.failures.push((i, e)); }
+    pub fn all_succeeded(&self) -> bool { self.failures.is_empty() }
+    pub fn success_count(&self) -> usize { self.successes.len() }
+    pub fn failure_count(&self) -> usize { self.failures.len() }
+    pub fn success_rate(&self) -> f64 { if self.total_processed == 0 { 0.0 } else { self.successes.len() as f64 / self.total_processed as f64 } }
+}
+impl<T, E> Default for BatchResult<T, E> { fn default() -> Self { Self::new() } }
+
+#[derive(Debug, Clone)]
+pub struct BatchError { pub message: String, pub index: usize, pub retryable: bool }
+impl BatchError { pub fn new(msg: impl Into<String>, idx: usize) -> Self { Self { message: msg.into(), index: idx, retryable: false } } pub fn retryable(mut self) -> Self { self.retryable = true; self } }
+impl std::fmt::Display for BatchError { fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result { write!(f, "Batch error at {}: {}", self.index, self.message) } }
+impl std::error::Error for BatchError {}
+
+#[derive(Debug, Clone, Copy, PartialEq, Eq)]
+pub enum BatchStrategy { Parallel, Sequential, Concurrent { max_concurrency: usize } }
+impl Default for BatchStrategy { fn default() -> Self { BatchStrategy::Concurrent { max_concurrency: 5 } } }
+
+#[derive(Debug, Clone)]
+pub struct BatchExecutorConfig { pub strategy: BatchStrategy, pub continue_on_error: bool, pub item_timeout: Option<Duration>, pub max_retries: u32 }
+impl Default for BatchExecutorConfig { fn default() -> Self { Self { strategy: BatchStrategy::default(), continue_on_error: true, item_timeout: Some(Duration::from_secs(60)), max_retries: 2 } } }
+impl BatchExecutorConfig {
+    pub fn new() -> Self { Self::default() }
+    pub fn with_strategy(mut self, s: BatchStrategy) -> Self { self.strategy = s; self }
+    pub fn with_continue_on_error(mut self, c: bool) -> Self { self.continue_on_error = c; self }
+}
+
+pub struct BatchExecutor { config: BatchExecutorConfig }
+impl BatchExecutor {
+    pub fn new() -> Self { Self { config: BatchExecutorConfig::default() } }
+    pub fn with_config(config: BatchExecutorConfig) -> Self { Self { config } }
+    pub fn config(&self) -> &BatchExecutorConfig { &self.config }
+
+    pub async fn execute_sequential<T, R, E, F, Fut>(&self, items: Vec<BatchItem<T>>, executor_fn: F) -> BatchResult<R, BatchError>
+    where F: Fn(T) -> Fut, Fut: std::future::Future<Output = std::result::Result<R, E>>, E: std::fmt::Display {
+        let start = Instant::now();
+        let total = items.len();
+        let mut result = BatchResult::new();
+        for (i, item) in items.into_iter().enumerate() {
+            match executor_fn(item.data).await {
+                Ok(r) => result.add_success(i, r),
+                Err(e) => { result.add_failure(i, BatchError::new(e.to_string(), i)); if !self.config.continue_on_error { break; } }
+            }
+        }
+        result.execution_time = start.elapsed();
+        result.total_processed = total;
+        result
+    }
+}
+impl Default for BatchExecutor { fn default() -> Self { Self::new() } }
diff --git a/src/batch/mod.rs b/src/batch/mod.rs
new file mode 100644
index 0000000..0bd4e8f
--- /dev/null
+++ b/src/batch/mod.rs
@@ -0,0 +1,7 @@
+//! Request batching module.
+
+mod collector;
+mod executor;
+
+pub use collector::{BatchCollector, BatchConfig, BatchItem, BatchAddResult};
+pub use executor::{BatchExecutor, BatchExecutorConfig, BatchResult, BatchError, BatchStrategy};
diff --git a/src/cache/backend.rs b/src/cache/backend.rs
new file mode 100644
index 0000000..4143664
--- /dev/null
+++ b/src/cache/backend.rs
@@ -0,0 +1,82 @@
+//! Cache backend implementations.
+
+use async_trait::async_trait;
+use std::collections::HashMap;
+use std::sync::{Arc, RwLock};
+use std::time::{Duration, Instant};
+use super::key::CacheKey;
+use crate::Result;
+
+#[derive(Clone)]
+struct CacheEntry { data: Vec<u8>, created_at: Instant, ttl: Duration, last_accessed: Instant }
+
+impl CacheEntry {
+    fn new(data: Vec<u8>, ttl: Duration) -> Self { let now = Instant::now(); Self { data, created_at: now, ttl, last_accessed: now } }
+    fn is_expired(&self) -> bool { self.created_at.elapsed() > self.ttl }
+}
+
+#[async_trait]
+pub trait CacheBackend: Send + Sync {
+    async fn get(&self, key: &CacheKey) -> Result<Option<Vec<u8>>>;
+    async fn set(&self, key: &CacheKey, value: &[u8], ttl: Duration) -> Result<()>;
+    async fn delete(&self, key: &CacheKey) -> Result<bool>;
+    async fn exists(&self, key: &CacheKey) -> Result<bool>;
+    async fn clear(&self) -> Result<()>;
+    async fn len(&self) -> Result<usize>;
+    fn name(&self) -> &'static str;
+}
+
+pub struct MemoryCache { entries: Arc<RwLock<HashMap<String, CacheEntry>>>, max_entries: usize }
+
+impl MemoryCache {
+    pub fn new(max_entries: usize) -> Self { Self { entries: Arc::new(RwLock::new(HashMap::new())), max_entries } }
+    fn evict_if_needed(&self, entries: &mut HashMap<String, CacheEntry>) {
+        entries.retain(|_, e| !e.is_expired());
+        while entries.len() >= self.max_entries {
+            let oldest = entries.iter().min_by_key(|(_, e)| e.last_accessed).map(|(k, _)| k.clone());
+            if let Some(k) = oldest { entries.remove(&k); } else { break; }
+        }
+    }
+}
+
+#[async_trait]
+impl CacheBackend for MemoryCache {
+    async fn get(&self, key: &CacheKey) -> Result<Option<Vec<u8>>> {
+        let mut entries = self.entries.write().unwrap();
+        if let Some(entry) = entries.get_mut(&key.hash) {
+            if entry.is_expired() { entries.remove(&key.hash); return Ok(None); }
+            entry.last_accessed = Instant::now();
+            return Ok(Some(entry.data.clone()));
+        }
+        Ok(None)
+    }
+    async fn set(&self, key: &CacheKey, value: &[u8], ttl: Duration) -> Result<()> {
+        let mut entries = self.entries.write().unwrap();
+        self.evict_if_needed(&mut entries);
+        entries.insert(key.hash.clone(), CacheEntry::new(value.to_vec(), ttl));
+        Ok(())
+    }
+    async fn delete(&self, key: &CacheKey) -> Result<bool> { Ok(self.entries.write().unwrap().remove(&key.hash).is_some()) }
+    async fn exists(&self, key: &CacheKey) -> Result<bool> {
+        let entries = self.entries.read().unwrap();
+        Ok(entries.get(&key.hash).map(|e| !e.is_expired()).unwrap_or(false))
+    }
+    async fn clear(&self) -> Result<()> { self.entries.write().unwrap().clear(); Ok(()) }
+    async fn len(&self) -> Result<usize> { Ok(self.entries.read().unwrap().values().filter(|e| !e.is_expired()).count()) }
+    fn name(&self) -> &'static str { "memory" }
+}
+
+pub struct NullCache;
+impl NullCache { pub fn new() -> Self { Self } }
+impl Default for NullCache { fn default() -> Self { Self::new() } }
+
+#[async_trait]
+impl CacheBackend for NullCache {
+    async fn get(&self, _: &CacheKey) -> Result<Option<Vec<u8>>> { Ok(None) }
+    async fn set(&self, _: &CacheKey, _: &[u8], _: Duration) -> Result<()> { Ok(()) }
+    async fn delete(&self, _: &CacheKey) -> Result<bool> { Ok(false) }
+    async fn exists(&self, _: &CacheKey) -> Result<bool> { Ok(false) }
+    async fn clear(&self) -> Result<()> { Ok(()) }
+    async fn len(&self) -> Result<usize> { Ok(0) }
+    fn name(&self) -> &'static str { "null" }
+}
diff --git a/src/cache/key.rs b/src/cache/key.rs
new file mode 100644
index 0000000..efea146
--- /dev/null
+++ b/src/cache/key.rs
@@ -0,0 +1,62 @@
+//! Cache key generation.
+
+use serde::{Deserialize, Serialize};
+use sha2::{Digest, Sha256};
+use std::collections::BTreeMap;
+
+#[derive(Debug, Clone, PartialEq, Eq, Hash, Serialize, Deserialize)]
+pub struct CacheKey {
+    pub hash: String,
+    pub model: Option<String>,
+    pub provider: Option<String>,
+    pub fingerprint: Option<String>,
+}
+
+impl CacheKey {
+    pub fn new(hash: impl Into<String>) -> Self {
+        Self { hash: hash.into(), model: None, provider: None, fingerprint: None }
+    }
+    pub fn with_model(mut self, model: impl Into<String>) -> Self { self.model = Some(model.into()); self }
+    pub fn with_provider(mut self, provider: impl Into<String>) -> Self { self.provider = Some(provider.into()); self }
+    pub fn with_fingerprint(mut self, fp: impl Into<String>) -> Self { self.fingerprint = Some(fp.into()); self }
+    pub fn as_str(&self) -> &str { &self.hash }
+}
+
+impl std::fmt::Display for CacheKey {
+    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result { write!(f, "{}", self.hash) }
+}
+
+impl From<&str> for CacheKey { fn from(s: &str) -> Self { Self::new(s) } }
+impl From<String> for CacheKey { fn from(s: String) -> Self { Self::new(s) } }
+
+pub struct CacheKeyGenerator {
+    include_model: bool,
+    include_temperature: bool,
+    salt: Option<String>,
+}
+
+impl CacheKeyGenerator {
+    pub fn new() -> Self { Self { include_model: true, include_temperature: true, salt: None } }
+    pub fn with_salt(mut self, salt: impl Into<String>) -> Self { self.salt = Some(salt.into()); self }
+
+    pub fn generate(&self, model: Option<&str>, messages: &[serde_json::Value], temperature: Option<f64>, _max_tokens: Option<u32>) -> CacheKey {
+        let mut parts: BTreeMap<String, String> = BTreeMap::new();
+        if self.include_model { if let Some(m) = model { parts.insert("model".into(), m.into()); } }
+        if self.include_temperature { if let Some(t) = temperature { parts.insert("temperature".into(), format!("{:.2}", t)); } }
+        parts.insert("messages".into(), serde_json::to_string(messages).unwrap_or_default());
+        if let Some(ref s) = self.salt { parts.insert("salt".into(), s.clone()); }
+        let canonical = serde_json::to_string(&parts).unwrap_or_default();
+        let mut hasher = Sha256::new();
+        hasher.update(canonical.as_bytes());
+        let hash: String = hasher.finalize().iter().map(|b| format!("{:02x}", b)).collect();
+        let mut key = CacheKey::new(hash);
+        if let Some(m) = model { key = key.with_model(m); }
+        key
+    }
+
+    pub fn generate_from_json(&self, request: &serde_json::Value) -> CacheKey {
+        self.generate(request["model"].as_str(), request["messages"].as_array().cloned().unwrap_or_default().as_slice(), request["temperature"].as_f64(), request["max_tokens"].as_u64().map(|v| v as u32))
+    }
+}
+
+impl Default for CacheKeyGenerator { fn default() -> Self { Self::new() } }
diff --git a/src/cache/manager.rs b/src/cache/manager.rs
new file mode 100644
index 0000000..e725c9d
--- /dev/null
+++ b/src/cache/manager.rs
@@ -0,0 +1,81 @@
+//! Cache manager.
+
+use serde::{de::DeserializeOwned, Serialize};
+use std::sync::atomic::{AtomicU64, Ordering};
+use std::sync::Arc;
+use std::time::Duration;
+use super::backend::CacheBackend;
+use super::key::CacheKey;
+use crate::Result;
+
+#[derive(Debug, Clone)]
+pub struct CacheConfig { pub default_ttl: Duration, pub enabled: bool, pub max_entry_size: usize, pub key_prefix: Option<String> }
+
+impl Default for CacheConfig {
+    fn default() -> Self { Self { default_ttl: Duration::from_secs(3600), enabled: true, max_entry_size: 10 * 1024 * 1024, key_prefix: None } }
+}
+
+impl CacheConfig {
+    pub fn new() -> Self { Self::default() }
+    pub fn with_ttl(mut self, ttl: Duration) -> Self { self.default_ttl = ttl; self }
+    pub fn with_enabled(mut self, enabled: bool) -> Self { self.enabled = enabled; self }
+    pub fn with_key_prefix(mut self, prefix: impl Into<String>) -> Self { self.key_prefix = Some(prefix.into()); self }
+}
+
+#[derive(Debug, Clone, Default)]
+pub struct CacheStats { pub hits: u64, pub misses: u64, pub sets: u64, pub deletes: u64, pub errors: u64 }
+
+impl CacheStats {
+    pub fn hit_ratio(&self) -> f64 { let total = self.hits + self.misses; if total == 0 { 0.0 } else { self.hits as f64 / total as f64 } }
+}
+
+struct AtomicStats { hits: AtomicU64, misses: AtomicU64, sets: AtomicU64, deletes: AtomicU64, errors: AtomicU64 }
+impl AtomicStats {
+    fn new() -> Self { Self { hits: AtomicU64::new(0), misses: AtomicU64::new(0), sets: AtomicU64::new(0), deletes: AtomicU64::new(0), errors: AtomicU64::new(0) } }
+    fn to_stats(&self) -> CacheStats { CacheStats { hits: self.hits.load(Ordering::Relaxed), misses: self.misses.load(Ordering::Relaxed), sets: self.sets.load(Ordering::Relaxed), deletes: self.deletes.load(Ordering::Relaxed), errors: self.errors.load(Ordering::Relaxed) } }
+}
+
+pub struct CacheManager { config: CacheConfig, backend: Box<dyn CacheBackend>, stats: Arc<AtomicStats> }
+
+impl CacheManager {
+    pub fn new(config: CacheConfig, backend: Box<dyn CacheBackend>) -> Self { Self { config, backend, stats: Arc::new(AtomicStats::new()) } }
+
+    pub async fn get<T: DeserializeOwned>(&self, key: &CacheKey) -> Result<Option<T>> {
+        if !self.config.enabled { return Ok(None); }
+        let prefixed = self.prefix_key(key);
+        match self.backend.get(&prefixed).await {
+            Ok(Some(data)) => {
+                self.stats.hits.fetch_add(1, Ordering::Relaxed);
+                match serde_json::from_slice(&data) {
+                    Ok(val) => Ok(Some(val)),
+                    Err(_) => { self.stats.errors.fetch_add(1, Ordering::Relaxed); Ok(None) }
+                }
+            }
+            Ok(None) => { self.stats.misses.fetch_add(1, Ordering::Relaxed); Ok(None) }
+            Err(e) => { self.stats.errors.fetch_add(1, Ordering::Relaxed); Err(e) }
+        }
+    }
+
+    pub async fn set<T: Serialize>(&self, key: &CacheKey, value: &T) -> Result<()> { self.set_with_ttl(key, value, self.config.default_ttl).await }
+
+    pub async fn set_with_ttl<T: Serialize>(&self, key: &CacheKey, value: &T, ttl: Duration) -> Result<()> {
+        if !self.config.enabled { return Ok(()); }
+        let data = serde_json::to_vec(value)?;
+        if data.len() > self.config.max_entry_size { return Ok(()); }
+        let prefixed = self.prefix_key(key);
+        match self.backend.set(&prefixed, &data, ttl).await { Ok(()) => { self.stats.sets.fetch_add(1, Ordering::Relaxed); Ok(()) } Err(e) => { self.stats.errors.fetch_add(1, Ordering::Relaxed); Err(e) } }
+    }
+
+    pub async fn delete(&self, key: &CacheKey) -> Result<bool> {
+        if !self.config.enabled { return Ok(false); }
+        let prefixed = self.prefix_key(key);
+        match self.backend.delete(&prefixed).await { Ok(d) => { if d { self.stats.deletes.fetch_add(1, Ordering::Relaxed); } Ok(d) } Err(e) => { self.stats.errors.fetch_add(1, Ordering::Relaxed); Err(e) } }
+    }
+
+    pub fn stats(&self) -> CacheStats { self.stats.to_stats() }
+    pub fn backend_name(&self) -> &'static str { self.backend.name() }
+
+    fn prefix_key(&self, key: &CacheKey) -> CacheKey {
+        if let Some(ref p) = self.config.key_prefix { CacheKey::new(format!("{}:{}", p, key.hash)) } else { key.clone() }
+    }
+}
diff --git a/src/cache/mod.rs b/src/cache/mod.rs
new file mode 100644
index 0000000..14583e9
--- /dev/null
+++ b/src/cache/mod.rs
@@ -0,0 +1,9 @@
+//! Response caching module.
+
+mod key;
+mod backend;
+mod manager;
+
+pub use key::{CacheKey, CacheKeyGenerator};
+pub use backend::{CacheBackend, MemoryCache, NullCache};
+pub use manager::{CacheManager, CacheConfig, CacheStats};
diff --git a/src/embeddings/client.rs b/src/embeddings/client.rs
new file mode 100644
index 0000000..95f6604
--- /dev/null
+++ b/src/embeddings/client.rs
@@ -0,0 +1,80 @@
+//! Embedding client for generating embeddings.
+
+use crate::{Error, ErrorContext, Result};
+use super::types::{Embedding, EmbeddingRequest, EmbeddingResponse, EmbeddingUsage};
+
+pub struct EmbeddingClient {
+    http_client: reqwest::Client,
+    model: String,
+    base_url: String,
+    api_key: String,
+    dimensions: Option<usize>,
+    max_batch_size: usize,
+}
+
+impl EmbeddingClient {
+    pub fn builder() -> EmbeddingClientBuilder { EmbeddingClientBuilder::new() }
+
+    pub async fn embed(&self, text: &str) -> Result<EmbeddingResponse> {
+        let request = EmbeddingRequest::single(&self.model, text);
+        self.execute(request).await
+    }
+
+    pub async fn embed_batch(&self, texts: &[impl AsRef<str>]) -> Result<EmbeddingResponse> {
+        let texts: Vec<String> = texts.iter().map(|t| t.as_ref().to_string()).collect();
+        if texts.len() <= self.max_batch_size {
+            return self.execute(EmbeddingRequest::batch(&self.model, texts)).await;
+        }
+        let mut all_embeddings: Vec<Embedding> = Vec::new();
+        let mut total_usage = EmbeddingUsage::default();
+        for (batch_idx, chunk) in texts.chunks(self.max_batch_size).enumerate() {
+            let response = self.execute(EmbeddingRequest::batch(&self.model, chunk.to_vec())).await?;
+            let offset = batch_idx * self.max_batch_size;
+            for mut emb in response.embeddings { emb.index += offset; all_embeddings.push(emb); }
+            total_usage.add(&response.usage);
+        }
+        Ok(EmbeddingResponse::new(all_embeddings, self.model.clone(), total_usage))
+    }
+
+    async fn execute(&self, mut request: EmbeddingRequest) -> Result<EmbeddingResponse> {
+        if let Some(dims) = self.dimensions { request = request.with_dimensions(dims); }
+        let endpoint = format!("{}/v1/embeddings", self.base_url);
+        let response = self.http_client.post(&endpoint).bearer_auth(&self.api_key).header("Content-Type", "application/json").json(&request).send().await
+            .map_err(|e| Error::network_with_context(format!("Embedding request failed: {}", e), ErrorContext::new().with_source("embeddings")))?;
+        let status = response.status();
+        let body = response.text().await.map_err(|e| Error::network_with_context(format!("Failed to read response: {}", e), ErrorContext::new()))?;
+        if !status.is_success() { return Err(Error::api_with_context(format!("Embedding API error ({}): {}", status, body), ErrorContext::new())); }
+        let json: serde_json::Value = serde_json::from_str(&body)?;
+        EmbeddingResponse::from_openai_format(&json)
+    }
+
+    pub fn model(&self) -> &str { &self.model }
+}
+
+pub struct EmbeddingClientBuilder {
+    model: Option<String>,
+    api_key: Option<String>,
+    base_url: Option<String>,
+    dimensions: Option<usize>,
+    max_batch_size: usize,
+    timeout_secs: u64,
+}
+
+impl EmbeddingClientBuilder {
+    pub fn new() -> Self { Self { model: None, api_key: None, base_url: None, dimensions: None, max_batch_size: 100, timeout_secs: 60 } }
+    pub fn model(mut self, model: impl Into<String>) -> Self { self.model = Some(model.into()); self }
+    pub fn api_key(mut self, api_key: impl Into<String>) -> Self { self.api_key = Some(api_key.into()); self }
+    pub fn base_url(mut self, url: impl Into<String>) -> Self { self.base_url = Some(url.into()); self }
+    pub fn dimensions(mut self, dimensions: usize) -> Self { self.dimensions = Some(dimensions); self }
+
+    pub async fn build(self) -> Result<EmbeddingClient> {
+        let model = self.model.ok_or_else(|| Error::configuration("Model must be specified"))?;
+        let api_key = self.api_key.or_else(|| std::env::var("OPENAI_API_KEY").ok()).ok_or_else(|| Error::configuration("API key required"))?;
+        let base_url = self.base_url.unwrap_or_else(|| "https://api.openai.com".to_string());
+        let http_client = reqwest::Client::builder().timeout(std::time::Duration::from_secs(self.timeout_secs)).build()
+            .map_err(|e| Error::configuration(format!("Failed to create HTTP client: {}", e)))?;
+        Ok(EmbeddingClient { http_client, model, base_url, api_key, dimensions: self.dimensions, max_batch_size: self.max_batch_size })
+    }
+}
+
+impl Default for EmbeddingClientBuilder { fn default() -> Self { Self::new() } }
diff --git a/src/embeddings/mod.rs b/src/embeddings/mod.rs
new file mode 100644
index 0000000..5b34298
--- /dev/null
+++ b/src/embeddings/mod.rs
@@ -0,0 +1,20 @@
+//! Embedding support for AI models.
+//!
+//! This module provides:
+//! - Embedding client for generating embeddings
+//! - Vector operations (similarity, distance, normalization)
+//! - Types for embedding requests and responses
+
+mod client;
+mod types;
+mod vectors;
+
+pub use client::{EmbeddingClient, EmbeddingClientBuilder};
+pub use types::{
+    Embedding, EmbeddingInput, EmbeddingModel, EmbeddingRequest, EmbeddingResponse, EmbeddingUsage,
+};
+pub use vectors::{
+    add_vectors, average_vectors, cosine_similarity, dot_product, euclidean_distance,
+    find_most_similar, magnitude, manhattan_distance, normalize_vector, scale_vector,
+    subtract_vectors, weighted_average_vectors, SimilarityMetric, SimilarityResult, Vector,
+};
diff --git a/src/embeddings/types.rs b/src/embeddings/types.rs
new file mode 100644
index 0000000..176b598
--- /dev/null
+++ b/src/embeddings/types.rs
@@ -0,0 +1,151 @@
+//! Embedding types and data structures.
+
+use serde::{Deserialize, Serialize};
+
+/// A single embedding vector with metadata.
+#[derive(Debug, Clone, Serialize, Deserialize)]
+pub struct Embedding {
+    pub index: usize,
+    pub vector: Vec<f32>,
+    #[serde(default = "default_object_type")]
+    pub object_type: String,
+}
+
+fn default_object_type() -> String {
+    "embedding".to_string()
+}
+
+impl Embedding {
+    pub fn new(index: usize, vector: Vec<f32>) -> Self {
+        Self { index, vector, object_type: "embedding".to_string() }
+    }
+
+    pub fn dimensions(&self) -> usize {
+        self.vector.len()
+    }
+}
+
+/// Request for generating embeddings.
+#[derive(Debug, Clone, Serialize, Deserialize)]
+pub struct EmbeddingRequest {
+    pub input: EmbeddingInput,
+    pub model: String,
+    #[serde(skip_serializing_if = "Option::is_none")]
+    pub dimensions: Option<usize>,
+    #[serde(skip_serializing_if = "Option::is_none")]
+    pub encoding_format: Option<String>,
+    #[serde(skip_serializing_if = "Option::is_none")]
+    pub user: Option<String>,
+}
+
+#[derive(Debug, Clone, Serialize, Deserialize)]
+#[serde(untagged)]
+pub enum EmbeddingInput {
+    Single(String),
+    Batch(Vec<String>),
+}
+
+impl EmbeddingRequest {
+    pub fn single(model: impl Into<String>, text: impl Into<String>) -> Self {
+        Self {
+            input: EmbeddingInput::Single(text.into()),
+            model: model.into(),
+            dimensions: None,
+            encoding_format: None,
+            user: None,
+        }
+    }
+
+    pub fn batch(model: impl Into<String>, texts: Vec<String>) -> Self {
+        Self {
+            input: EmbeddingInput::Batch(texts),
+            model: model.into(),
+            dimensions: None,
+            encoding_format: None,
+            user: None,
+        }
+    }
+
+    pub fn with_dimensions(mut self, dimensions: usize) -> Self {
+        self.dimensions = Some(dimensions);
+        self
+    }
+}
+
+#[derive(Debug, Clone, Default, Serialize, Deserialize)]
+pub struct EmbeddingUsage {
+    pub prompt_tokens: u32,
+    pub total_tokens: u32,
+}
+
+impl EmbeddingUsage {
+    pub fn new(prompt_tokens: u32) -> Self {
+        Self { prompt_tokens, total_tokens: prompt_tokens }
+    }
+
+    pub fn add(&mut self, other: &EmbeddingUsage) {
+        self.prompt_tokens += other.prompt_tokens;
+        self.total_tokens += other.total_tokens;
+    }
+}
+
+#[derive(Debug, Clone, Serialize, Deserialize)]
+pub struct EmbeddingResponse {
+    pub embeddings: Vec<Embedding>,
+    pub model: String,
+    pub usage: EmbeddingUsage,
+    #[serde(default = "default_list_type")]
+    pub object: String,
+}
+
+fn default_list_type() -> String { "list".to_string() }
+
+impl EmbeddingResponse {
+    pub fn new(embeddings: Vec<Embedding>, model: String, usage: EmbeddingUsage) -> Self {
+        Self { embeddings, model, usage, object: "list".to_string() }
+    }
+
+    pub fn first(&self) -> Option<&Embedding> { self.embeddings.first() }
+    pub fn len(&self) -> usize { self.embeddings.len() }
+    pub fn is_empty(&self) -> bool { self.embeddings.is_empty() }
+
+    pub fn from_openai_format(data: &serde_json::Value) -> crate::Result<Self> {
+        let embeddings = data["data"]
+            .as_array()
+            .ok_or_else(|| crate::Error::parsing("Missing 'data' array"))?
+            .iter()
+            .map(|item| {
+                let index = item["index"].as_u64().unwrap_or(0) as usize;
+                let vector: Vec<f32> = item["embedding"]
+                    .as_array()
+                    .map(|arr| arr.iter().filter_map(|v| v.as_f64().map(|f| f as f32)).collect())
+                    .unwrap_or_default();
+                Embedding::new(index, vector)
+            })
+            .collect();
+        let model = data["model"].as_str().unwrap_or("unknown").to_string();
+        let usage = EmbeddingUsage {
+            prompt_tokens: data["usage"]["prompt_tokens"].as_u64().unwrap_or(0) as u32,
+            total_tokens: data["usage"]["total_tokens"].as_u64().unwrap_or(0) as u32,
+        };
+        Ok(Self::new(embeddings, model, usage))
+    }
+}
+
+#[derive(Debug, Clone, Serialize, Deserialize)]
+pub struct EmbeddingModel {
+    pub id: String,
+    pub name: String,
+    pub max_input_tokens: u32,
+    pub dimensions: usize,
+    pub provider: String,
+}
+
+impl EmbeddingModel {
+    pub fn text_embedding_3_small() -> Self {
+        Self { id: "text-embedding-3-small".into(), name: "Text Embedding 3 Small".into(), max_input_tokens: 8191, dimensions: 1536, provider: "openai".into() }
+    }
+    pub fn text_embedding_3_large() -> Self {
+        Self { id: "text-embedding-3-large".into(), name: "Text Embedding 3 Large".into(), max_input_tokens: 8191, dimensions: 3072, provider: "openai".into() }
+    }
+}
diff --git a/src/embeddings/vectors.rs b/src/embeddings/vectors.rs
new file mode 100644
index 0000000..cd99543
--- /dev/null
+++ b/src/embeddings/vectors.rs
@@ -0,0 +1,111 @@
+//! Vector operations for embeddings.
+
+use crate::{Error, Result};
+
+pub type Vector = Vec<f32>;
+
+pub fn dot_product(a: &[f32], b: &[f32]) -> Result<f32> {
+    if a.len() != b.len() {
+        return Err(Error::validation(format!("Vector dimensions must match: {} != {}", a.len(), b.len())));
+    }
+    Ok(a.iter().zip(b.iter()).map(|(x, y)| x * y).sum())
+}
+
+pub fn magnitude(v: &[f32]) -> f32 {
+    v.iter().map(|x| x * x).sum::<f32>().sqrt()
+}
+
+pub fn normalize_vector(v: &[f32]) -> Vector {
+    let mag = magnitude(v);
+    if mag == 0.0 { return v.to_vec(); }
+    v.iter().map(|x| x / mag).collect()
+}
+
+pub fn cosine_similarity(a: &[f32], b: &[f32]) -> Result<f32> {
+    if a.len() != b.len() {
+        return Err(Error::validation(format!("Vector dimensions must match: {} != {}", a.len(), b.len())));
+    }
+    let dot = dot_product(a, b)?;
+    let mag_a = magnitude(a);
+    let mag_b = magnitude(b);
+    if mag_a == 0.0 || mag_b == 0.0 { return Ok(0.0); }
+    Ok(dot / (mag_a * mag_b))
+}
+
+pub fn euclidean_distance(a: &[f32], b: &[f32]) -> Result<f32> {
+    if a.len() != b.len() {
+        return Err(Error::validation(format!("Vector dimensions must match: {} != {}", a.len(), b.len())));
+    }
+    Ok(a.iter().zip(b.iter()).map(|(x, y)| (x - y).powi(2)).sum::<f32>().sqrt())
+}
+
+pub fn manhattan_distance(a: &[f32], b: &[f32]) -> Result<f32> {
+    if a.len() != b.len() {
+        return Err(Error::validation(format!("Vector dimensions must match: {} != {}", a.len(), b.len())));
+    }
+    Ok(a.iter().zip(b.iter()).map(|(x, y)| (x - y).abs()).sum())
+}
+
+#[derive(Debug, Clone, Copy, PartialEq, Eq)]
+pub enum SimilarityMetric { Cosine, Euclidean, DotProduct, Manhattan }
+
+#[derive(Debug, Clone)]
+pub struct SimilarityResult { pub index: usize, pub score: f32 }
+
+pub fn find_most_similar(query: &[f32], candidates: &[Vec<f32>], top_k: usize, metric: SimilarityMetric) -> Result<Vec<SimilarityResult>> {
+    let mut scores: Vec<SimilarityResult> = candidates.iter().enumerate()
+        .filter_map(|(i, c)| {
+            let score = match metric {
+                SimilarityMetric::Cosine => cosine_similarity(query, c).ok(),
+                SimilarityMetric::Euclidean => euclidean_distance(query, c).ok(),
+                SimilarityMetric::DotProduct => dot_product(query, c).ok(),
+                SimilarityMetric::Manhattan => manhattan_distance(query, c).ok(),
+            };
+            score.map(|s| SimilarityResult { index: i, score: s })
+        }).collect();
+    match metric {
+        SimilarityMetric::Cosine | SimilarityMetric::DotProduct => scores.sort_by(|a, b| b.score.partial_cmp(&a.score).unwrap_or(std::cmp::Ordering::Equal)),
+        _ => scores.sort_by(|a, b| a.score.partial_cmp(&b.score).unwrap_or(std::cmp::Ordering::Equal)),
+    }
+    scores.truncate(top_k);
+    Ok(scores)
+}
+
+pub fn average_vectors(vectors: &[Vec<f32>]) -> Result<Vector> {
+    if vectors.is_empty() { return Err(Error::validation("Cannot average empty list")); }
+    let dim = vectors[0].len();
+    if !vectors.iter().all(|v| v.len() == dim) { return Err(Error::validation("All vectors must have same dimensions")); }
+    let n = vectors.len() as f32;
+    let mut result = vec![0.0; dim];
+    for v in vectors { for (i, val) in v.iter().enumerate() { result[i] += val; } }
+    for val in &mut result { *val /= n; }
+    Ok(result)
+}
+
+pub fn weighted_average_vectors(vectors: &[Vec<f32>], weights: &[f32]) -> Result<Vector> {
+    if vectors.is_empty() { return Err(Error::validation("Cannot average empty list")); }
+    if vectors.len() != weights.len() { return Err(Error::validation("Vectors and weights must match")); }
+    let total: f32 = weights.iter().sum();
+    if total == 0.0 { return Err(Error::validation("Total weight cannot be zero")); }
+    let dim = vectors[0].len();
+    let mut result = vec![0.0; dim];
+    for (v, w) in vectors.iter().zip(weights.iter()) {
+        let nw = w / total;
+        for (i, val) in v.iter().enumerate() { result[i] += val * nw; }
+    }
+    Ok(result)
+}
+
+pub fn add_vectors(a: &[f32], b: &[f32]) -> Result<Vector> {
+    if a.len() != b.len() { return Err(Error::validation("Dimensions must match")); }
+    Ok(a.iter().zip(b.iter()).map(|(x, y)| x + y).collect())
+}
+
+pub fn subtract_vectors(a: &[f32], b: &[f32]) -> Result<Vector> {
+    if a.len() != b.len() { return Err(Error::validation("Dimensions must match")); }
+    Ok(a.iter().zip(b.iter()).map(|(x, y)| x - y).collect())
+}
+
+pub fn scale_vector(v: &[f32], scalar: f32) -> Vector {
+    v.iter().map(|x| x * scalar).collect()
+}
diff --git a/src/error.rs b/src/error.rs
index 2fb86b1..88d1a82 100644
--- a/src/error.rs
+++ b/src/error.rs
@@ -225,6 +225,40 @@ impl Error {
         }
     }
 
+    /// Create a simple validation error
+    pub fn validation(msg: impl Into<String>) -> Self {
+        Self::validation_with_context(msg, ErrorContext::new())
+    }
+
+    /// Create a simple configuration error
+    pub fn configuration(msg: impl Into<String>) -> Self {
+        Self::configuration_with_context(msg, ErrorContext::new())
+    }
+
+    /// Create a network error with context
+    pub fn network_with_context(msg: impl Into<String>, context: ErrorContext) -> Self {
+        Error::Runtime {
+            message: format!("Network error: {}", msg.into()),
+            context,
+        }
+    }
+
+    /// Create an API error with context
+    pub fn api_with_context(msg: impl Into<String>, context: ErrorContext) -> Self {
+        Error::Runtime {
+            message: format!("API error: {}", msg.into()),
+            context,
+        }
+    }
+
+    /// Create a parsing error
+    pub fn parsing(msg: impl Into<String>) -> Self {
+        Error::Validation {
+            message: format!("Parsing error: {}", msg.into()),
+            context: ErrorContext::new().with_source("parsing"),
+        }
+    }
+
     /// Extract error context if available
     pub fn context(&self) -> Option<&ErrorContext> {
         match self {
diff --git a/src/lib.rs b/src/lib.rs
index 84098cf..4c7efa8 100644
--- a/src/lib.rs
+++ b/src/lib.rs
@@ -7,11 +7,16 @@
 //! for interacting with AI models across different providers without hardcoding
 //! provider-specific logic.
 
+pub mod batch;
+pub mod cache;
 pub mod client;
+pub mod embeddings;
 pub mod pipeline;
+pub mod plugins;
 pub mod protocol;
 pub mod resilience;
 pub mod telemetry;
+pub mod tokens;
 pub mod transport;
 pub mod types;
 pub mod utils;
diff --git a/src/plugins/base.rs b/src/plugins/base.rs
new file mode 100644
index 0000000..696b83f
--- /dev/null
+++ b/src/plugins/base.rs
@@ -0,0 +1,63 @@
+//! Base plugin types.
+
+use async_trait::async_trait;
+use std::collections::HashMap;
+use std::sync::Arc;
+use crate::Result;
+
+#[derive(Debug, Clone, Copy, PartialEq, Eq, PartialOrd, Ord)]
+pub enum PluginPriority { Highest = 0, High = 25, Normal = 50, Low = 75, Lowest = 100 }
+impl Default for PluginPriority { fn default() -> Self { PluginPriority::Normal } }
+
+#[derive(Debug, Clone, Default)]
+pub struct PluginContext {
+    pub request: Option<serde_json::Value>,
+    pub response: Option<serde_json::Value>,
+    pub request_id: Option<String>,
+    pub model: Option<String>,
+    pub provider: Option<String>,
+    pub metadata: HashMap<String, serde_json::Value>,
+    pub error: Option<String>,
+    pub skip: bool,
+}
+
+impl PluginContext {
+    pub fn new() -> Self { Self::default() }
+    pub fn with_request(mut self, r: serde_json::Value) -> Self { self.request = Some(r); self }
+    pub fn with_request_id(mut self, id: impl Into<String>) -> Self { self.request_id = Some(id.into()); self }
+    pub fn with_model(mut self, m: impl Into<String>) -> Self { self.model = Some(m.into()); self }
+    pub fn skip(&mut self) { self.skip = true; }
+    pub fn should_skip(&self) -> bool { self.skip }
+    pub fn set_error(&mut self, e: impl Into<String>) { self.error = Some(e.into()); }
+    pub fn has_error(&self) -> bool { self.error.is_some() }
+}
+
+#[async_trait]
+pub trait Plugin: Send + Sync {
+    fn name(&self) -> &str;
+    fn priority(&self) -> PluginPriority { PluginPriority::Normal }
+    async fn on_register(&self) -> Result<()> { Ok(()) }
+    async fn on_unregister(&self) -> Result<()> { Ok(()) }
+    async fn on_before_request(&self, _ctx: &mut PluginContext) -> Result<()> { Ok(()) }
+    async fn on_after_response(&self, _ctx: &mut PluginContext) -> Result<()> { Ok(()) }
+    async fn on_error(&self, _ctx: &mut PluginContext) -> Result<()> { Ok(()) }
+    async fn on_stream_event(&self, _ctx: &mut PluginContext, _event: &serde_json::Value) -> Result<()> { Ok(()) }
+}
+
+pub struct CompositePlugin { name: String, plugins: Vec<Arc<dyn Plugin>> }
+impl CompositePlugin {
+    pub fn new(name: impl Into<String>) -> Self { Self { name: name.into(), plugins: Vec::new() } }
+    pub fn add(mut self, p: Arc<dyn Plugin>) -> Self { self.plugins.push(p); self }
+    pub fn len(&self) -> usize { self.plugins.len() }
+    pub fn is_empty(&self) -> bool { self.plugins.is_empty() }
+}
+
+#[async_trait]
+impl Plugin for CompositePlugin {
+    fn name(&self) -> &str { &self.name }
+    async fn on_register(&self) -> Result<()> { for p in &self.plugins { p.on_register().await?; } Ok(()) }
+    async fn on_unregister(&self) -> Result<()> { for p in &self.plugins { p.on_unregister().await?; } Ok(()) }
+    async fn on_before_request(&self, ctx: &mut PluginContext) -> Result<()> { for p in &self.plugins { if ctx.should_skip() { break; } p.on_before_request(ctx).await?; } Ok(()) }
+    async fn on_after_response(&self, ctx: &mut PluginContext) -> Result<()> { for p in &self.plugins { if ctx.should_skip() { break; } p.on_after_response(ctx).await?; } Ok(()) }
+    async fn on_error(&self, ctx: &mut PluginContext) -> Result<()> { for p in &self.plugins { p.on_error(ctx).await?; } Ok(()) }
+}
diff --git a/src/plugins/hooks.rs b/src/plugins/hooks.rs
new file mode 100644
index 0000000..7019021
--- /dev/null
+++ b/src/plugins/hooks.rs
@@ -0,0 +1,57 @@
+//! Hook system.
+
+use async_trait::async_trait;
+use std::collections::HashMap;
+use std::sync::{Arc, RwLock};
+use super::base::PluginContext;
+use crate::Result;
+
+#[derive(Debug, Clone, Copy, PartialEq, Eq, Hash)]
+pub enum HookType { BeforeRequest, AfterResponse, OnError, OnStreamEvent, OnRetry, OnFallback, OnCacheHit, OnCacheMiss }
+
+#[async_trait]
+pub trait AsyncHook: Send + Sync { async fn call(&self, ctx: &mut PluginContext) -> Result<()>; }
+
+pub struct Hook { pub name: String, pub priority: i32, callback: Arc<dyn AsyncHook> }
+impl Hook {
+    pub fn new<H: AsyncHook + 'static>(name: impl Into<String>, priority: i32, callback: H) -> Self { Self { name: name.into(), priority, callback: Arc::new(callback) } }
+    pub async fn call(&self, ctx: &mut PluginContext) -> Result<()> { self.callback.call(ctx).await }
+}
+
+pub struct FnHook<F> { func: F }
+impl<F> FnHook<F> where F: Fn(&mut PluginContext) -> Result<()> + Send + Sync { pub fn new(func: F) -> Self { Self { func } } }
+#[async_trait]
+impl<F> AsyncHook for FnHook<F> where F: Fn(&mut PluginContext) -> Result<()> + Send + Sync { async fn call(&self, ctx: &mut PluginContext) -> Result<()> { (self.func)(ctx) } }
+
+pub struct HookManager { hooks: RwLock<HashMap<HookType, Vec<Hook>>> }
+impl HookManager {
+    pub fn new() -> Self { Self { hooks: RwLock::new(HashMap::new()) } }
+
+    pub fn register(&self, hook_type: HookType, hook: Hook) {
+        let mut hooks = self.hooks.write().unwrap();
+        let entry = hooks.entry(hook_type).or_insert_with(Vec::new);
+        entry.push(hook);
+        entry.sort_by_key(|h| h.priority);
+    }
+
+    pub fn register_fn<F>(&self, hook_type: HookType, name: impl Into<String>, priority: i32, func: F)
+    where F: Fn(&mut PluginContext) -> Result<()> + Send + Sync + 'static {
+        self.register(hook_type, Hook::new(name, priority, FnHook::new(func)));
+    }
+
+    pub fn unregister(&self, hook_type: HookType, name: &str) -> bool {
+        let mut hooks = self.hooks.write().unwrap();
+        if let Some(entry) = hooks.get_mut(&hook_type) { let len = entry.len(); entry.retain(|h| h.name != name); return entry.len() < len; }
+        false
+    }
+
+    pub async fn trigger(&self, hook_type: HookType, ctx: &mut PluginContext) -> Result<()> {
+        let callbacks: Vec<Arc<dyn AsyncHook>> = { let hooks = self.hooks.read().unwrap(); hooks.get(&hook_type).map(|v| v.iter().map(|h| h.callback.clone()).collect()).unwrap_or_default() };
+        for cb in callbacks { if ctx.should_skip() { break; } cb.call(ctx).await?; }
+        Ok(())
+    }
+
+    pub fn count(&self, hook_type: HookType) -> usize { self.hooks.read().unwrap().get(&hook_type).map(|v| v.len()).unwrap_or(0) }
+    pub fn clear(&self) { self.hooks.write().unwrap().clear(); }
+}
+impl Default for HookManager { fn default() -> Self { Self::new() } }
diff --git a/src/plugins/middleware.rs b/src/plugins/middleware.rs
new file mode 100644
index 0000000..a526e69
--- /dev/null
+++ b/src/plugins/middleware.rs
@@ -0,0 +1,49 @@
+//! Middleware system.
+
+use async_trait::async_trait;
+use std::sync::Arc;
+use crate::Result;
+
+#[derive(Debug, Clone)]
+pub struct MiddlewareContext {
+    pub request: serde_json::Value,
+    pub response: Option<serde_json::Value>,
+    pub request_id: Option<String>,
+    pub model: Option<String>,
+    pub metadata: std::collections::HashMap<String, serde_json::Value>,
+}
+
+impl MiddlewareContext {
+    pub fn new(request: serde_json::Value) -> Self { Self { request, response: None, request_id: None, model: None, metadata: std::collections::HashMap::new() } }
+    pub fn set_response(&mut self, r: serde_json::Value) { self.response = Some(r); }
+    pub fn with_request_id(mut self, id: impl Into<String>) -> Self { self.request_id = Some(id.into()); self }
+    pub fn with_model(mut self, m: impl Into<String>) -> Self { self.model = Some(m.into()); self }
+}
+
+pub type NextFn<'a> = Box<dyn FnOnce(MiddlewareContext) -> std::pin::Pin<Box<dyn std::future::Future<Output = Result<MiddlewareContext>> + Send + 'a>> + Send + 'a>;
+
+#[async_trait]
+pub trait Middleware: Send + Sync {
+    async fn process(&self, ctx: MiddlewareContext, next: NextFn<'_>) -> Result<MiddlewareContext>;
+    fn name(&self) -> &str { "unnamed" }
+}
+
+pub struct MiddlewareChain { middlewares: Vec<Arc<dyn Middleware>> }
+impl MiddlewareChain {
+    pub fn new() -> Self { Self { middlewares: Vec::new() } }
+    pub fn add(mut self, m: Arc<dyn Middleware>) -> Self { self.middlewares.push(m); self }
+    pub fn len(&self) -> usize { self.middlewares.len() }
+    pub fn is_empty(&self) -> bool { self.middlewares.is_empty() }
+
+    pub async fn execute<F, Fut>(&self, ctx: MiddlewareContext, handler: F) -> Result<MiddlewareContext>
+    where F: FnOnce(MiddlewareContext) -> Fut + Send + 'static, Fut: std::future::Future<Output = Result<MiddlewareContext>> + Send + 'static {
+        if self.middlewares.is_empty() { return handler(ctx).await; }
+        let mut current = ctx;
+        for mw in &self.middlewares {
+            let next: NextFn<'_> = Box::new(move |c| Box::pin(async move { Ok(c) }));
+            current = mw.process(current, next).await?;
+        }
+        handler(current).await
+    }
+}
+impl Default for MiddlewareChain { fn default() -> Self { Self::new() } }
diff --git a/src/plugins/mod.rs b/src/plugins/mod.rs
new file mode 100644
index 0000000..0a3c59b
--- /dev/null
+++ b/src/plugins/mod.rs
@@ -0,0 +1,11 @@
+//! Plugin and middleware system.
+
+mod base;
+mod hooks;
+mod middleware;
+mod registry;
+
+pub use base::{Plugin, PluginContext, PluginPriority, CompositePlugin};
+pub use hooks::{Hook, HookType, HookManager, AsyncHook, FnHook};
+pub use middleware::{Middleware, MiddlewareChain, MiddlewareContext};
+pub use registry::{PluginRegistry, get_plugin_registry};
diff --git a/src/plugins/registry.rs b/src/plugins/registry.rs
new file mode 100644
index 0000000..dc5be07
--- /dev/null
+++ b/src/plugins/registry.rs
@@ -0,0 +1,61 @@
+//! Plugin registry.
+
+use std::collections::HashMap;
+use std::sync::{Arc, RwLock};
+use super::base::{Plugin, PluginContext};
+use crate::Result;
+
+pub struct PluginRegistry { plugins: RwLock<HashMap<String, Arc<dyn Plugin>>>, enabled: RwLock<bool> }
+
+impl PluginRegistry {
+    pub fn new() -> Self { Self { plugins: RwLock::new(HashMap::new()), enabled: RwLock::new(true) } }
+
+    pub async fn register(&self, plugin: Arc<dyn Plugin>) -> Result<()> {
+        let name = plugin.name().to_string();
+        plugin.on_register().await?;
+        self.plugins.write().unwrap().insert(name, plugin);
+        Ok(())
+    }
+
+    pub async fn unregister(&self, name: &str) -> Result<Option<Arc<dyn Plugin>>> {
+        let plugin = self.plugins.write().unwrap().remove(name);
+        if let Some(ref p) = plugin { p.on_unregister().await?; }
+        Ok(plugin)
+    }
+
+    pub fn get(&self, name: &str) -> Option<Arc<dyn Plugin>> { self.plugins.read().unwrap().get(name).cloned() }
+    pub fn has(&self, name: &str) -> bool { self.plugins.read().unwrap().contains_key(name) }
+    pub fn list(&self) -> Vec<Arc<dyn Plugin>> { self.plugins.read().unwrap().values().cloned().collect() }
+    pub fn list_by_priority(&self) -> Vec<Arc<dyn Plugin>> { let mut p = self.list(); p.sort_by_key(|x| x.priority()); p }
+    pub fn count(&self) -> usize { self.plugins.read().unwrap().len() }
+    pub fn set_enabled(&self, e: bool) { *self.enabled.write().unwrap() = e; }
+    pub fn is_enabled(&self) -> bool { *self.enabled.read().unwrap() }
+
+    pub async fn trigger_before_request(&self, ctx: &mut PluginContext) -> Result<()> {
+        if !self.is_enabled() { return Ok(()); }
+        for p in self.list_by_priority() { if ctx.should_skip() { break; } p.on_before_request(ctx).await?; }
+        Ok(())
+    }
+
+    pub async fn trigger_after_response(&self, ctx: &mut PluginContext) -> Result<()> {
+        if !self.is_enabled() { return Ok(()); }
+        for p in self.list_by_priority() { if ctx.should_skip() { break; } p.on_after_response(ctx).await?; }
+        Ok(())
+    }
+
+    pub async fn trigger_on_error(&self, ctx: &mut PluginContext) -> Result<()> {
+        if !self.is_enabled() { return Ok(()); }
+        for p in self.list_by_priority() { p.on_error(ctx).await?; }
+        Ok(())
+    }
+
+    pub async fn clear(&self) -> Result<()> {
+        let plugins: HashMap<_, _> = std::mem::take(&mut *self.plugins.write().unwrap());
+        for (_, p) in plugins { let _ = p.on_unregister().await; }
+        Ok(())
+    }
+}
+impl Default for PluginRegistry { fn default() -> Self { Self::new() } }
+
+static GLOBAL_REGISTRY: once_cell::sync::Lazy<PluginRegistry> = once_cell::sync::Lazy::new(PluginRegistry::new);
+pub fn get_plugin_registry() -> &'static PluginRegistry { &GLOBAL_REGISTRY }
diff --git a/src/telemetry/mod.rs b/src/telemetry/mod.rs
index bba8b5b..b99f3e8 100644
--- a/src/telemetry/mod.rs
+++ b/src/telemetry/mod.rs
@@ -7,47 +7,160 @@
 
 use crate::Result;
 use async_trait::async_trait;
-use std::sync::Arc;
+use serde::{Deserialize, Serialize};
+use std::sync::{Arc, RwLock};
+use std::time::{SystemTime, UNIX_EPOCH};
 
-/// Minimal user feedback for multi-candidate selection.
-#[derive(Debug, Clone)]
+fn timestamp() -> f64 { SystemTime::now().duration_since(UNIX_EPOCH).map(|d| d.as_secs_f64()).unwrap_or(0.0) }
+
+/// Feedback for multi-candidate selection.
+#[derive(Debug, Clone, Serialize, Deserialize)]
 pub struct ChoiceSelectionFeedback {
-    /// Request identifier emitted by the runtime (`client_request_id`).
     pub request_id: String,
-    /// The chosen candidate index (0-based).
     pub chosen_index: u32,
-    /// Optional rejected indices (0-based).
     pub rejected_indices: Option<Vec<u32>>,
-    /// Time from render to selection (ms), if the UI can measure it.
     pub latency_to_select_ms: Option<u64>,
-    /// Optional UI context (component name / experiment id / etc.)
     pub ui_context: Option<serde_json::Value>,
-    /// Optional content hashes to link choice to rendered candidates without uploading text.
     pub candidate_hashes: Option<Vec<String>>,
+    pub timestamp: f64,
+}
+
+impl ChoiceSelectionFeedback {
+    pub fn new(request_id: impl Into<String>, chosen_index: u32) -> Self {
+        Self { request_id: request_id.into(), chosen_index, rejected_indices: None, latency_to_select_ms: None, ui_context: None, candidate_hashes: None, timestamp: timestamp() }
+    }
+    pub fn with_rejected(mut self, indices: Vec<u32>) -> Self { self.rejected_indices = Some(indices); self }
+    pub fn with_latency(mut self, ms: u64) -> Self { self.latency_to_select_ms = Some(ms); self }
+}
+
+/// Rating feedback (e.g., 1-5 stars).
+#[derive(Debug, Clone, Serialize, Deserialize)]
+pub struct RatingFeedback {
+    pub request_id: String, pub rating: u32, pub max_rating: u32, pub category: Option<String>, pub comment: Option<String>, pub timestamp: f64,
+}
+impl RatingFeedback {
+    pub fn new(request_id: impl Into<String>, rating: u32) -> Self { Self { request_id: request_id.into(), rating, max_rating: 5, category: None, comment: None, timestamp: timestamp() } }
+    pub fn with_max_rating(mut self, m: u32) -> Self { self.max_rating = m; self }
+    pub fn with_comment(mut self, c: impl Into<String>) -> Self { self.comment = Some(c.into()); self }
+}
+
+/// Thumbs up/down feedback.
+#[derive(Debug, Clone, Serialize, Deserialize)]
+pub struct ThumbsFeedback { pub request_id: String, pub is_positive: bool, pub reason: Option<String>, pub timestamp: f64 }
+impl ThumbsFeedback {
+    pub fn thumbs_up(request_id: impl Into<String>) -> Self { Self { request_id: request_id.into(), is_positive: true, reason: None, timestamp: timestamp() } }
+    pub fn thumbs_down(request_id: impl Into<String>) -> Self { Self { request_id: request_id.into(), is_positive: false, reason: None, timestamp: timestamp() } }
+    pub fn with_reason(mut self, r: impl Into<String>) -> Self { self.reason = Some(r.into()); self }
+}
+
+/// Free-form text feedback.
+#[derive(Debug, Clone, Serialize, Deserialize)]
+pub struct TextFeedback { pub request_id: String, pub text: String, pub category: Option<String>, pub timestamp: f64 }
+impl TextFeedback {
+    pub fn new(request_id: impl Into<String>, text: impl Into<String>) -> Self { Self { request_id: request_id.into(), text: text.into(), category: None, timestamp: timestamp() } }
+}
+
+/// Correction feedback.
+#[derive(Debug, Clone, Serialize, Deserialize)]
+pub struct CorrectionFeedback { pub request_id: String, pub original_hash: String, pub corrected_hash: String, pub edit_distance: Option<u32>, pub correction_type: Option<String>, pub timestamp: f64 }
+impl CorrectionFeedback {
+    pub fn new(request_id: impl Into<String>, original: impl Into<String>, corrected: impl Into<String>) -> Self {
+        Self { request_id: request_id.into(), original_hash: original.into(), corrected_hash: corrected.into(), edit_distance: None, correction_type: None, timestamp: timestamp() }
+    }
 }
 
+/// Regeneration feedback.
+#[derive(Debug, Clone, Serialize, Deserialize)]
+pub struct RegenerateFeedback { pub request_id: String, pub regeneration_count: u32, pub reason: Option<String>, pub timestamp: f64 }
+impl RegenerateFeedback { pub fn new(request_id: impl Into<String>) -> Self { Self { request_id: request_id.into(), regeneration_count: 1, reason: None, timestamp: timestamp() } } }
+
+/// Stop generation feedback.
+#[derive(Debug, Clone, Serialize, Deserialize)]
+pub struct StopFeedback { pub request_id: String, pub tokens_generated: Option<u32>, pub reason: Option<String>, pub timestamp: f64 }
+impl StopFeedback { pub fn new(request_id: impl Into<String>) -> Self { Self { request_id: request_id.into(), tokens_generated: None, reason: None, timestamp: timestamp() } } }
+
 /// Typed feedback events (extensible).
-#[derive(Debug, Clone)]
+#[derive(Debug, Clone, Serialize, Deserialize)]
 pub enum FeedbackEvent {
     ChoiceSelection(ChoiceSelectionFeedback),
+    Rating(RatingFeedback),
+    Thumbs(ThumbsFeedback),
+    Text(TextFeedback),
+    Correction(CorrectionFeedback),
+    Regenerate(RegenerateFeedback),
+    Stop(StopFeedback),
 }
 
-/// Feedback sink hook. Applications decide whether and where to store/report feedback.
+impl FeedbackEvent {
+    pub fn request_id(&self) -> &str {
+        match self {
+            FeedbackEvent::ChoiceSelection(f) => &f.request_id,
+            FeedbackEvent::Rating(f) => &f.request_id,
+            FeedbackEvent::Thumbs(f) => &f.request_id,
+            FeedbackEvent::Text(f) => &f.request_id,
+            FeedbackEvent::Correction(f) => &f.request_id,
+            FeedbackEvent::Regenerate(f) => &f.request_id,
+            FeedbackEvent::Stop(f) => &f.request_id,
+        }
+    }
+}
+
+/// Feedback sink trait.
 #[async_trait]
 pub trait FeedbackSink: Send + Sync {
     async fn report(&self, event: FeedbackEvent) -> Result<()>;
+    async fn report_batch(&self, events: Vec<FeedbackEvent>) -> Result<()> { for e in events { self.report(e).await?; } Ok(()) }
+    async fn close(&self) -> Result<()> { Ok(()) }
 }
 
-/// Default sink: do nothing.
+/// No-op sink.
 pub struct NoopFeedbackSink;
+#[async_trait]
+impl FeedbackSink for NoopFeedbackSink { async fn report(&self, _: FeedbackEvent) -> Result<()> { Ok(()) } }
 
+/// In-memory sink for testing.
+pub struct InMemoryFeedbackSink { events: Arc<RwLock<Vec<FeedbackEvent>>>, max_events: usize }
+impl InMemoryFeedbackSink {
+    pub fn new(max: usize) -> Self { Self { events: Arc::new(RwLock::new(Vec::new())), max_events: max } }
+    pub fn get_events(&self) -> Vec<FeedbackEvent> { self.events.read().unwrap().clone() }
+    pub fn get_events_by_request(&self, req_id: &str) -> Vec<FeedbackEvent> { self.events.read().unwrap().iter().filter(|e| e.request_id() == req_id).cloned().collect() }
+    pub fn clear(&self) { self.events.write().unwrap().clear(); }
+    pub fn len(&self) -> usize { self.events.read().unwrap().len() }
+    pub fn is_empty(&self) -> bool { self.len() == 0 }
+}
 #[async_trait]
-impl FeedbackSink for NoopFeedbackSink {
-    async fn report(&self, _event: FeedbackEvent) -> Result<()> {
+impl FeedbackSink for InMemoryFeedbackSink {
+    async fn report(&self, event: FeedbackEvent) -> Result<()> {
+        let mut events = self.events.write().unwrap();
+        events.push(event);
+        if events.len() > self.max_events { events.remove(0); }
         Ok(())
     }
 }
 
-pub fn noop_sink() -> Arc<dyn FeedbackSink> {
-    Arc::new(NoopFeedbackSink)
+/// Console sink for debugging.
+pub struct ConsoleFeedbackSink { prefix: String }
+impl ConsoleFeedbackSink { pub fn new(prefix: impl Into<String>) -> Self { Self { prefix: prefix.into() } } }
+impl Default for ConsoleFeedbackSink { fn default() -> Self { Self::new("[Feedback]") } }
+#[async_trait]
+impl FeedbackSink for ConsoleFeedbackSink { async fn report(&self, event: FeedbackEvent) -> Result<()> { println!("{} {:?}", self.prefix, event); Ok(()) } }
+
+/// Composite sink for multiple destinations.
+pub struct CompositeFeedbackSink { sinks: Vec<Arc<dyn FeedbackSink>> }
+impl CompositeFeedbackSink {
+    pub fn new() -> Self { Self { sinks: Vec::new() } }
+    pub fn add_sink(mut self, sink: Arc<dyn FeedbackSink>) -> Self { self.sinks.push(sink); self }
+}
+impl Default for CompositeFeedbackSink { fn default() -> Self { Self::new() } }
+#[async_trait]
+impl FeedbackSink for CompositeFeedbackSink {
+    async fn report(&self, event: FeedbackEvent) -> Result<()> { for s in &self.sinks { let _ = s.report(event.clone()).await; } Ok(()) }
+    async fn close(&self) -> Result<()> { for s in &self.sinks { let _ = s.close().await; } Ok(()) }
 }
+
+pub fn noop_sink() -> Arc<dyn FeedbackSink> { Arc::new(NoopFeedbackSink) }
+
+static GLOBAL_SINK: once_cell::sync::Lazy<RwLock<Arc<dyn FeedbackSink>>> = once_cell::sync::Lazy::new(|| RwLock::new(Arc::new(NoopFeedbackSink)));
+pub fn get_feedback_sink() -> Arc<dyn FeedbackSink> { GLOBAL_SINK.read().unwrap().clone() }
+pub fn set_feedback_sink(sink: Arc<dyn FeedbackSink>) { *GLOBAL_SINK.write().unwrap() = sink; }
+pub async fn report_feedback(event: FeedbackEvent) -> Result<()> { get_feedback_sink().report(event).await }
diff --git a/src/tokens/counter.rs b/src/tokens/counter.rs
new file mode 100644
index 0000000..bf45694
--- /dev/null
+++ b/src/tokens/counter.rs
@@ -0,0 +1,91 @@
+//! Token counter implementations.
+
+use std::collections::HashMap;
+use std::sync::{Arc, RwLock};
+use crate::types::Message;
+use crate::types::message::{ContentBlock, MessageContent};
+
+pub trait TokenCounter: Send + Sync {
+    fn count(&self, text: &str) -> usize;
+
+    fn count_messages(&self, messages: &[Message]) -> usize {
+        let mut total = 0;
+        for message in messages {
+            total += 1;
+            match &message.content {
+                MessageContent::Text(text) => { total += self.count(text); }
+                MessageContent::Blocks(blocks) => {
+                    for block in blocks {
+                        match block {
+                            ContentBlock::Text { text } => { total += self.count(text); }
+                            ContentBlock::Image { .. } => { total += 85; }
+                            ContentBlock::Audio { .. } => { total += 100; }
+                            ContentBlock::ToolUse { input, .. } => { total += self.count(&serde_json::to_string(input).unwrap_or_default()); }
+                            ContentBlock::ToolResult { content, .. } => { total += self.count(&serde_json::to_string(content).unwrap_or_default()); }
+                        }
+                    }
+                }
+            }
+        }
+        total + messages.len() * 3
+    }
+
+    fn truncate_to_limit(&self, text: &str, max_tokens: usize, suffix: &str) -> String {
+        let current = self.count(text);
+        if current <= max_tokens { return text.to_string(); }
+        let suffix_tokens = if suffix.is_empty() { 0 } else { self.count(suffix) };
+        let target = max_tokens.saturating_sub(suffix_tokens);
+        if target == 0 { return suffix.to_string(); }
+        let chars_per_token = text.len() as f64 / current as f64;
+        let mut truncated: String = text.chars().take((target as f64 * chars_per_token) as usize).collect();
+        while self.count(&truncated) > target && !truncated.is_empty() { truncated = truncated.chars().take((truncated.len() as f64 * 0.9) as usize).collect(); }
+        format!("{}{}", truncated, suffix)
+    }
+}
+
+#[derive(Debug, Clone)]
+pub struct CharacterEstimator { chars_per_token: f64 }
+impl CharacterEstimator {
+    pub fn new() -> Self { Self::with_ratio(4.0) }
+    pub fn with_ratio(r: f64) -> Self { Self { chars_per_token: r } }
+}
+impl Default for CharacterEstimator { fn default() -> Self { Self::new() } }
+impl TokenCounter for CharacterEstimator { fn count(&self, text: &str) -> usize { (text.len() as f64 / self.chars_per_token).ceil() as usize } }
+
+#[derive(Debug, Clone)]
+pub struct AnthropicEstimator { chars_per_token: f64 }
+impl AnthropicEstimator { pub fn new() -> Self { Self { chars_per_token: 3.5 } } }
+impl Default for AnthropicEstimator { fn default() -> Self { Self::new() } }
+impl TokenCounter for AnthropicEstimator {
+    fn count(&self, text: &str) -> usize {
+        let base = (text.len() as f64 / self.chars_per_token).ceil() as usize;
+        let ws = text.chars().filter(|c| c.is_whitespace()).count();
+        base + (ws as f64 * 0.1) as usize
+    }
+}
+
+pub struct CachingCounter { inner: Box<dyn TokenCounter>, cache: Arc<RwLock<HashMap<String, usize>>>, max_size: usize }
+impl CachingCounter {
+    pub fn new(inner: Box<dyn TokenCounter>, max_size: usize) -> Self { Self { inner, cache: Arc::new(RwLock::new(HashMap::new())), max_size } }
+    pub fn clear_cache(&self) { self.cache.write().unwrap().clear(); }
+}
+impl TokenCounter for CachingCounter {
+    fn count(&self, text: &str) -> usize {
+        { let c = self.cache.read().unwrap(); if let Some(&n) = c.get(text) { return n; } }
+        let n = self.inner.count(text);
+        { let mut c = self.cache.write().unwrap(); if c.len() < self.max_size { c.insert(text.to_string(), n); } }
+        n
+    }
+}
+
+static COUNTERS: once_cell::sync::Lazy<RwLock<HashMap<String, Arc<dyn TokenCounter>>>> = once_cell::sync::Lazy::new(|| RwLock::new(HashMap::new()));
+
+pub fn get_token_counter(model: &str) -> Arc<dyn TokenCounter> {
+    let ml = model.to_lowercase();
+    { let c = COUNTERS.read().unwrap(); if let Some(x) = c.get(&ml) { return x.clone(); } }
+    let counter: Arc<dyn TokenCounter> = if ml.contains("gpt") || ml.contains("o1") { Arc::new(CharacterEstimator::new()) }
+    else if ml.contains("claude") { Arc::new(AnthropicEstimator::new()) }
+    else { Arc::new(CharacterEstimator::new()) };
+    { let mut c = COUNTERS.write().unwrap(); c.insert(ml, counter.clone()); }
+    counter
+}
diff --git a/src/tokens/mod.rs b/src/tokens/mod.rs
new file mode 100644
index 0000000..c1c3145
--- /dev/null
+++ b/src/tokens/mod.rs
@@ -0,0 +1,7 @@
+//! Token counting and cost estimation.
+
+mod counter;
+mod pricing;
+
+pub use counter::{TokenCounter, CharacterEstimator, CachingCounter, AnthropicEstimator, get_token_counter};
+pub use pricing::{ModelPricing, CostEstimate};
diff --git a/src/tokens/pricing.rs b/src/tokens/pricing.rs
new file mode 100644
index 0000000..2ad9538
--- /dev/null
+++ b/src/tokens/pricing.rs
@@ -0,0 +1,35 @@
+//! Model pricing and cost estimation.
+
+use serde::{Deserialize, Serialize};
+
+#[derive(Debug, Clone, Serialize, Deserialize)]
+pub struct ModelPricing { pub model: String, pub input_cost_per_1k: f64, pub output_cost_per_1k: f64, pub currency: String }
+
+impl ModelPricing {
+    pub fn new(model: &str, input: f64, output: f64) -> Self { Self { model: model.into(), input_cost_per_1k: input, output_cost_per_1k: output, currency: "USD".into() } }
+    pub fn calculate_cost(&self, input_tokens: u32, output_tokens: u32) -> CostEstimate {
+        let ic = (input_tokens as f64 / 1000.0) * self.input_cost_per_1k;
+        let oc = (output_tokens as f64 / 1000.0) * self.output_cost_per_1k;
+        CostEstimate { model: self.model.clone(), input_tokens, output_tokens, input_cost: ic, output_cost: oc, total_cost: ic + oc, currency: self.currency.clone() }
+    }
+    pub fn gpt_4o() -> Self { Self::new("gpt-4o", 0.005, 0.015) }
+    pub fn gpt_4o_mini() -> Self { Self::new("gpt-4o-mini", 0.00015, 0.0006) }
+    pub fn claude_35_sonnet() -> Self { Self::new("claude-3-5-sonnet", 0.003, 0.015) }
+    pub fn claude_3_haiku() -> Self { Self::new("claude-3-haiku", 0.00025, 0.00125) }
+    pub fn for_model(model: &str) -> Option<Self> {
+        let m = model.to_lowercase();
+        if m.contains("gpt-4o-mini") { Some(Self::gpt_4o_mini()) }
+        else if m.contains("gpt-4o") { Some(Self::gpt_4o()) }
+        else if m.contains("claude-3-5-sonnet") { Some(Self::claude_35_sonnet()) }
+        else if m.contains("claude-3-haiku") { Some(Self::claude_3_haiku()) }
+        else { None }
+    }
+}
+
+#[derive(Debug, Clone, Serialize, Deserialize)]
+pub struct CostEstimate { pub model: String, pub input_tokens: u32, pub output_tokens: u32, pub input_cost: f64, pub output_cost: f64, pub total_cost: f64, pub currency: String }
+
+impl CostEstimate {
+    pub fn format(&self) -> String { format!("{} {:.6}", self.currency, self.total_cost) }
+    pub fn format_detailed(&self) -> String { if self.total_cost < 0.01 { format!("{:.4}", self.total_cost * 100.0) } else { format!("${:.4}", self.total_cost) } }
+}
-- 
2.43.0

